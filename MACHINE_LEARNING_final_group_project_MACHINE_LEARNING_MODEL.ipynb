{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sethi-rasna/Wine_Os/blob/main/MACHINE_LEARNING_final_group_project_MACHINE_LEARNING_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install postgresql server\n",
        "!sudo apt-get -y -qq update\n",
        "!sudo apt-get -y -qq install postgresql\n",
        "!sudo service postgresql start\n",
        "\n",
        "# Setup a password `postgres` for username `postgres`\n",
        "!sudo -u postgres psql -U postgres -c \"ALTER USER postgres PASSWORD 'postgres';\"\n",
        "\n",
        "# Setup a database with name `tfio_demo` to be used\n",
        "!sudo -u postgres psql -U postgres -c 'DROP DATABASE IF EXISTS Red_White_Wine;'\n",
        "!sudo -u postgres psql -U postgres -c 'CREATE DATABASE Red_White_Wine;'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvynOZHfCRMa",
        "outputId": "917b0f50-b4cf-4c8d-d80b-2aba7d38b691"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../0-cron_3.0pl1-128.1ubuntu1.2_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128.1ubuntu1.2) ...\n",
            "Selecting previously unselected package logrotate.\n",
            "Preparing to unpack .../1-logrotate_3.11.0-0.1ubuntu1_amd64.deb ...\n",
            "Unpacking logrotate (3.11.0-0.1ubuntu1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../2-netbase_5.4_all.deb ...\n",
            "Unpacking netbase (5.4) ...\n",
            "Selecting previously unselected package postgresql-client-common.\n",
            "Preparing to unpack .../3-postgresql-client-common_190ubuntu0.1_all.deb ...\n",
            "Unpacking postgresql-client-common (190ubuntu0.1) ...\n",
            "Selecting previously unselected package postgresql-client-10.\n",
            "Preparing to unpack .../4-postgresql-client-10_10.22-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking postgresql-client-10 (10.22-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package ssl-cert.\n",
            "Preparing to unpack .../5-ssl-cert_1.0.39_all.deb ...\n",
            "Unpacking ssl-cert (1.0.39) ...\n",
            "Selecting previously unselected package postgresql-common.\n",
            "Preparing to unpack .../6-postgresql-common_190ubuntu0.1_all.deb ...\n",
            "Adding 'diversion of /usr/bin/pg_config to /usr/bin/pg_config.libpq-dev by postgresql-common'\n",
            "Unpacking postgresql-common (190ubuntu0.1) ...\n",
            "Selecting previously unselected package postgresql-10.\n",
            "Preparing to unpack .../7-postgresql-10_10.22-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking postgresql-10 (10.22-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package postgresql.\n",
            "Preparing to unpack .../8-postgresql_10+190ubuntu0.1_all.deb ...\n",
            "Unpacking postgresql (10+190ubuntu0.1) ...\n",
            "Selecting previously unselected package sysstat.\n",
            "Preparing to unpack .../9-sysstat_11.6.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking sysstat (11.6.1-1ubuntu0.1) ...\n",
            "Setting up sysstat (11.6.1-1ubuntu0.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/default/sysstat with new version\n",
            "update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.\n",
            "Setting up ssl-cert (1.0.39) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up cron (3.0pl1-128.1ubuntu1.2) ...\n",
            "Adding group `crontab' (GID 110) ...\n",
            "Done.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/cron.service → /lib/systemd/system/cron.service.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up logrotate (3.11.0-0.1ubuntu1) ...\n",
            "Setting up netbase (5.4) ...\n",
            "Setting up postgresql-client-common (190ubuntu0.1) ...\n",
            "Setting up postgresql-common (190ubuntu0.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Adding user postgres to group ssl-cert\n",
            "\n",
            "Creating config file /etc/postgresql-common/createcluster.conf with new version\n",
            "Building PostgreSQL dictionaries from installed myspell/hunspell packages...\n",
            "Removing obsolete dictionary files:\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service → /lib/systemd/system/postgresql.service.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up postgresql-client-10 (10.22-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/share/postgresql/10/man/man1/psql.1.gz to provide /usr/share/man/man1/psql.1.gz (psql.1.gz) in auto mode\n",
            "Setting up postgresql-10 (10.22-0ubuntu0.18.04.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Creating new PostgreSQL cluster 10/main ...\n",
            "/usr/lib/postgresql/10/bin/initdb -D /var/lib/postgresql/10/main --auth-local peer --auth-host md5\n",
            "The files belonging to this database system will be owned by user \"postgres\".\n",
            "This user must also own the server process.\n",
            "\n",
            "The database cluster will be initialized with locale \"en_US.UTF-8\".\n",
            "The default database encoding has accordingly been set to \"UTF8\".\n",
            "The default text search configuration will be set to \"english\".\n",
            "\n",
            "Data page checksums are disabled.\n",
            "\n",
            "fixing permissions on existing directory /var/lib/postgresql/10/main ... ok\n",
            "creating subdirectories ... ok\n",
            "selecting default max_connections ... 100\n",
            "selecting default shared_buffers ... 128MB\n",
            "selecting default timezone ... Etc/UTC\n",
            "selecting dynamic shared memory implementation ... posix\n",
            "creating configuration files ... ok\n",
            "running bootstrap script ... ok\n",
            "performing post-bootstrap initialization ... ok\n",
            "syncing data to disk ... ok\n",
            "\n",
            "Success. You can now start the database server using:\n",
            "\n",
            "    /usr/lib/postgresql/10/bin/pg_ctl -D /var/lib/postgresql/10/main -l logfile start\n",
            "\n",
            "Ver Cluster Port Status Owner    Data directory              Log file\n",
            "\u001b[31m10  main    5432 down   postgres /var/lib/postgresql/10/main /var/log/postgresql/postgresql-10-main.log\u001b[0m\n",
            "update-alternatives: using /usr/share/postgresql/10/man/man1/postmaster.1.gz to provide /usr/share/man/man1/postmaster.1.gz (postmaster.1.gz) in auto mode\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up postgresql (10+190ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for systemd (237-3ubuntu10.56) ...\n",
            " * Starting PostgreSQL 10 database server\n",
            "   ...done.\n",
            "ALTER ROLE\n",
            "NOTICE:  database \"red_white_wine\" does not exist, skipping\n",
            "DROP DATABASE\n",
            "CREATE DATABASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env Red_White_Wine_DATABASE_NAME=Red_White_Wine\n",
        "%env Red_White_Wine_DATABASE_HOST=localhost\n",
        "%env Red_White_Wine_DATABASE_PORT=5432\n",
        "%env Red_White_Wine_DATABASE_USER=postgres\n",
        "%env Red_White_Wine_DATABASE_PASS=!Hebob77"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBixpUGONqLM",
        "outputId": "72ad8176-0784-4091-a05d-3915c46649b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: Red_White_Wine_DATABASE_NAME=Red_White_Wine\n",
            "env: Red_White_Wine_DATABASE_HOST=localhost\n",
            "env: Red_White_Wine_DATABASE_PORT=5432\n",
            "env: Red_White_Wine_DATABASE_USER=postgres\n",
            "env: Red_White_Wine_DATABASE_PASS=!Hebob77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "upload =  files.upload()"
      ],
      "metadata": {
        "id": "p9KA0Sr2O06p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "1a6ccbf1-89c5-46d9-a572-c25617dbc52f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c0a1162-8a71-4290-bf38-86051b001b7f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c0a1162-8a71-4290-bf38-86051b001b7f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving red_white.csv to red_white.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Dependencies**"
      ],
      "metadata": {
        "id": "BAouqhibb7HE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ga1j0QycZrUC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "e064b625-6b5e-41c7-8cd0-f01ba1a82d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  wine_type  winetype_numeric  fixed acidity  volatile acidity  citric acid  \\\n",
              "0     white                 2            3.8             0.310         0.02   \n",
              "1     white                 2            3.9             0.225         0.40   \n",
              "2     white                 2            4.4             0.460         0.10   \n",
              "3     white                 2            4.8             0.225         0.38   \n",
              "4     white                 2            4.8             0.170         0.28   \n",
              "\n",
              "   residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
              "0            11.1      0.036                 20.0                 114.0   \n",
              "1             4.2      0.030                 29.0                 118.0   \n",
              "2             2.8      0.024                 31.0                 111.0   \n",
              "3             1.2      0.074                 47.0                 130.0   \n",
              "4             2.9      0.030                 22.0                 111.0   \n",
              "\n",
              "   density    pH  sulphates  alcohol  fixed acidity.1  sulphates 1=low 2=high  \\\n",
              "0  0.99248  3.75       0.44     12.4              3.8                       1   \n",
              "1  0.98900  3.57       0.36     12.8              3.9                       1   \n",
              "2  0.98816  3.48       0.34     13.1              4.4                       1   \n",
              "3  0.99132  3.31       0.40     10.3              4.8                       1   \n",
              "4  0.99020  3.38       0.34     11.3              4.8                       1   \n",
              "\n",
              "   alcohol 1=low 2=high  fixed acidity 1=low 2=high  healthiness  quality  \n",
              "0                     2                           1            1        2  \n",
              "1                     2                           1            1        2  \n",
              "2                     2                           1            1        2  \n",
              "3                     2                           1            1        2  \n",
              "4                     2                           1            1        2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-485f4078-a60b-42d7-9f6f-0f0cb0739aec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_type</th>\n",
              "      <th>winetype_numeric</th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>fixed acidity.1</th>\n",
              "      <th>sulphates 1=low 2=high</th>\n",
              "      <th>alcohol 1=low 2=high</th>\n",
              "      <th>fixed acidity 1=low 2=high</th>\n",
              "      <th>healthiness</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.1</td>\n",
              "      <td>0.036</td>\n",
              "      <td>20.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>0.99248</td>\n",
              "      <td>3.75</td>\n",
              "      <td>0.44</td>\n",
              "      <td>12.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.40</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.030</td>\n",
              "      <td>29.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.98900</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.36</td>\n",
              "      <td>12.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.460</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.024</td>\n",
              "      <td>31.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.98816</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.34</td>\n",
              "      <td>13.1</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.074</td>\n",
              "      <td>47.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>0.99132</td>\n",
              "      <td>3.31</td>\n",
              "      <td>0.40</td>\n",
              "      <td>10.3</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>white</td>\n",
              "      <td>2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.030</td>\n",
              "      <td>22.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99020</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.34</td>\n",
              "      <td>11.3</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-485f4078-a60b-42d7-9f6f-0f0cb0739aec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-485f4078-a60b-42d7-9f6f-0f0cb0739aec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-485f4078-a60b-42d7-9f6f-0f0cb0739aec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Import our input dataset\n",
        "application_df = pd.read_csv('red_white.csv')\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XA0e7dE6aowK"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "ixGYYdW2byHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ICLEv9w2WMHh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "f2bb3c7f-3182-49b1-dd67-e20cbd00a5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   winetype_numeric  fixed acidity  residual sugar  density    pH  sulphates  \\\n",
              "0                 2            3.8            11.1  0.99248  3.75       0.44   \n",
              "1                 2            3.9             4.2  0.98900  3.57       0.36   \n",
              "2                 2            4.4             2.8  0.98816  3.48       0.34   \n",
              "3                 2            4.8             1.2  0.99132  3.31       0.40   \n",
              "4                 2            4.8             2.9  0.99020  3.38       0.34   \n",
              "5                 2            4.8             1.1  0.99246  3.32       0.36   \n",
              "6                 1            5.0             1.4  0.99380  3.75       0.48   \n",
              "7                 2            5.0             1.5  0.99170  3.48       0.44   \n",
              "8                 2            5.0             1.5  0.99060  3.48       0.39   \n",
              "9                 2            5.0             4.5  0.98956  3.45       0.31   \n",
              "\n",
              "   alcohol  fixed acidity.1  sulphates 1=low 2=high  alcohol 1=low 2=high  \\\n",
              "0     12.4              3.8                       1                     2   \n",
              "1     12.8              3.9                       1                     2   \n",
              "2     13.1              4.4                       1                     2   \n",
              "3     10.3              4.8                       1                     2   \n",
              "4     11.3              4.8                       1                     2   \n",
              "5     13.5              4.8                       1                     2   \n",
              "6     10.5              5.0                       1                     2   \n",
              "7     10.7              5.0                       1                     2   \n",
              "8     10.8              5.0                       1                     2   \n",
              "9     12.6              5.0                       1                     2   \n",
              "\n",
              "   fixed acidity 1=low 2=high  healthiness  quality  \n",
              "0                           1            1        2  \n",
              "1                           1            1        2  \n",
              "2                           1            1        2  \n",
              "3                           1            1        2  \n",
              "4                           1            1        2  \n",
              "5                           1            1        2  \n",
              "6                           1            1        2  \n",
              "7                           1            1        2  \n",
              "8                           1            1        2  \n",
              "9                           1            1        2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f00b2ea6-a047-4fe3-8140-4c415a2085fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>winetype_numeric</th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>fixed acidity.1</th>\n",
              "      <th>sulphates 1=low 2=high</th>\n",
              "      <th>alcohol 1=low 2=high</th>\n",
              "      <th>fixed acidity 1=low 2=high</th>\n",
              "      <th>healthiness</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>3.8</td>\n",
              "      <td>11.1</td>\n",
              "      <td>0.99248</td>\n",
              "      <td>3.75</td>\n",
              "      <td>0.44</td>\n",
              "      <td>12.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.98900</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.36</td>\n",
              "      <td>12.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.98816</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.34</td>\n",
              "      <td>13.1</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.99132</td>\n",
              "      <td>3.31</td>\n",
              "      <td>0.40</td>\n",
              "      <td>10.3</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.99020</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.34</td>\n",
              "      <td>11.3</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.99246</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>13.5</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.99380</td>\n",
              "      <td>3.75</td>\n",
              "      <td>0.48</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.99170</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.99060</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.39</td>\n",
              "      <td>10.8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.98956</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.31</td>\n",
              "      <td>12.6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f00b2ea6-a047-4fe3-8140-4c415a2085fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f00b2ea6-a047-4fe3-8140-4c415a2085fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f00b2ea6-a047-4fe3-8140-4c415a2085fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Drop the non-beneficial ID columns, 'volatile acidity','citric acid', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide'.\n",
        "application_df = application_df.drop(['wine_type','volatile acidity','citric acid', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide'],1)\n",
        "application_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AfTKCZ7uvlAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7680e54a-1392-4253-d2d9-9eca69ed2a9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "winetype_numeric                2\n",
              "fixed acidity                 102\n",
              "residual sugar                254\n",
              "density                       752\n",
              "pH                             98\n",
              "sulphates                     108\n",
              "alcohol                        84\n",
              "fixed acidity.1               102\n",
              "sulphates 1=low 2=high          2\n",
              "alcohol 1=low 2=high            2\n",
              "fixed acidity 1=low 2=high      2\n",
              "healthiness                     2\n",
              "quality                         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at winetype_numeric value counts for binning\n",
        "application_count = application_df.winetype_numeric.value_counts()\n",
        "application_count\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cpchu9PyDPk",
        "outputId": "88ee68f1-c2cb-4fa5-8b36-2ab497395d18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1470\n",
              "1    1470\n",
              "Name: winetype_numeric, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate our categorical variable lists \n",
        "#application_cat = application_df.dtypes[application_df.dtypes == 'object'].index.tolist()\n",
        "#application_df[application_cat].nunique()"
      ],
      "metadata": {
        "id": "IUTzNsJF2PRe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define \"healthy\" column with metrics scores based on sulphate content. IF low then 1= HEALTHY If high then 2= NOT HEALTHY \n",
        "\n",
        "y = application_df[['healthiness','quality']].values\n",
        "X = application_df.drop(['healthiness','quality'],1).values \n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "id": "ny4_AbQPEk9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6718c045-b262-45e9-bd5d-21345ed3fa67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "UFKLCusBjjNR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile, Train, and Evaluate the Model**"
      ],
      "metadata": {
        "id": "bhyobLVOeUUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 80\n",
        "hidden_nodes_layer2 = 30\n",
        "\n",
        "nn = Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(Dense(units=hidden_nodes_layer1,input_dim=number_input_features,activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(Dense(units=hidden_nodes_layer2,activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(units=2,activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bn0kGsGXM4Y",
        "outputId": "bf56eec6-28d5-4235-fe51-903d2f01f0fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 80)                960       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 62        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452\n",
            "Trainable params: 3,452\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8C2sR4eqXNTy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ls4p61IXNmH",
        "outputId": "dc28cffd-dda5-48b5-d33e-58074d6a2a99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "69/69 [==============================] - 1s 2ms/step - loss: -1.5968 - accuracy: 0.3492\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -15.3816 - accuracy: 0.5215\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -80.0536 - accuracy: 0.6930\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -260.9406 - accuracy: 0.8082\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -627.0150 - accuracy: 0.8222\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1241.3762 - accuracy: 0.8063\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2165.1682 - accuracy: 0.8063\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3449.0420 - accuracy: 0.8063\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -5154.5010 - accuracy: 0.8063\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -7318.3408 - accuracy: 0.8063\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -9988.4473 - accuracy: 0.8063\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -13168.7432 - accuracy: 0.8063\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -16938.9629 - accuracy: 0.8063\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -21277.0273 - accuracy: 0.8063\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -26263.9121 - accuracy: 0.8063\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -31868.8828 - accuracy: 0.8063\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -38204.2852 - accuracy: 0.8063\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -45265.4570 - accuracy: 0.8063\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -53125.5352 - accuracy: 0.8063\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -61792.2266 - accuracy: 0.8063\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -71251.9844 - accuracy: 0.8063\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -81507.4688 - accuracy: 0.8063\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -92670.7812 - accuracy: 0.8063\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -104641.9062 - accuracy: 0.8063\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -117464.6094 - accuracy: 0.8063\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -131221.0938 - accuracy: 0.8063\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -145881.3750 - accuracy: 0.8063\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -161454.9531 - accuracy: 0.8063\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -177911.8594 - accuracy: 0.8063\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -195306.9062 - accuracy: 0.8063\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -213665.2656 - accuracy: 0.8063\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -232945.5781 - accuracy: 0.8063\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -253166.2344 - accuracy: 0.8063\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -274376.2500 - accuracy: 0.8063\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -296552.4688 - accuracy: 0.8063\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -319765.3125 - accuracy: 0.8063\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -343940.6250 - accuracy: 0.8063\n",
            "Epoch 38/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -369155.7812 - accuracy: 0.8063\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -395360.0000 - accuracy: 0.8063\n",
            "Epoch 40/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -422590.1875 - accuracy: 0.8063\n",
            "Epoch 41/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -450916.5625 - accuracy: 0.8063\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -480255.3750 - accuracy: 0.8063\n",
            "Epoch 43/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -510696.9688 - accuracy: 0.8063\n",
            "Epoch 44/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -542222.4375 - accuracy: 0.8063\n",
            "Epoch 45/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -574692.1875 - accuracy: 0.8063\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -608391.7500 - accuracy: 0.8063\n",
            "Epoch 47/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -643056.1250 - accuracy: 0.8063\n",
            "Epoch 48/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -678919.5000 - accuracy: 0.8063\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -715840.7500 - accuracy: 0.8063\n",
            "Epoch 50/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -753819.1875 - accuracy: 0.8063\n",
            "Epoch 51/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -792972.9375 - accuracy: 0.8063\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -833165.9375 - accuracy: 0.8063\n",
            "Epoch 53/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -874561.2500 - accuracy: 0.8063\n",
            "Epoch 54/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -917022.8125 - accuracy: 0.8063\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -960731.8750 - accuracy: 0.8063\n",
            "Epoch 56/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1005555.2500 - accuracy: 0.8063\n",
            "Epoch 57/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1051615.8750 - accuracy: 0.8063\n",
            "Epoch 58/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1098848.8750 - accuracy: 0.8063\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1147218.1250 - accuracy: 0.8063\n",
            "Epoch 60/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1196861.0000 - accuracy: 0.8063\n",
            "Epoch 61/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1247673.5000 - accuracy: 0.8063\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1299693.1250 - accuracy: 0.8063\n",
            "Epoch 63/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1352929.0000 - accuracy: 0.8063\n",
            "Epoch 64/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1407357.5000 - accuracy: 0.8063\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1463051.5000 - accuracy: 0.8063\n",
            "Epoch 66/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1519990.2500 - accuracy: 0.8063\n",
            "Epoch 67/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1578168.7500 - accuracy: 0.8063\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1637620.1250 - accuracy: 0.8063\n",
            "Epoch 69/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1698342.6250 - accuracy: 0.8063\n",
            "Epoch 70/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1760022.1250 - accuracy: 0.8063\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1823327.3750 - accuracy: 0.8063\n",
            "Epoch 72/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1887806.1250 - accuracy: 0.8063\n",
            "Epoch 73/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -1953386.1250 - accuracy: 0.8063\n",
            "Epoch 74/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2020540.5000 - accuracy: 0.8063\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2089035.8750 - accuracy: 0.8063\n",
            "Epoch 76/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2158557.2500 - accuracy: 0.8063\n",
            "Epoch 77/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2229670.2500 - accuracy: 0.8063\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2302027.7500 - accuracy: 0.8063\n",
            "Epoch 79/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2375720.0000 - accuracy: 0.8063\n",
            "Epoch 80/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2450798.2500 - accuracy: 0.8063\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2527245.5000 - accuracy: 0.8063\n",
            "Epoch 82/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2605070.7500 - accuracy: 0.8063\n",
            "Epoch 83/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2684252.2500 - accuracy: 0.8063\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -2764701.7500 - accuracy: 0.8063\n",
            "Epoch 85/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2846841.5000 - accuracy: 0.8063\n",
            "Epoch 86/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -2930025.5000 - accuracy: 0.8063\n",
            "Epoch 87/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3014713.2500 - accuracy: 0.8063\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3100994.2500 - accuracy: 0.8063\n",
            "Epoch 89/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3188484.2500 - accuracy: 0.8063\n",
            "Epoch 90/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3277366.5000 - accuracy: 0.8063\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3367705.7500 - accuracy: 0.8063\n",
            "Epoch 92/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3459756.5000 - accuracy: 0.8063\n",
            "Epoch 93/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3552704.7500 - accuracy: 0.8063\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3648008.2500 - accuracy: 0.8063\n",
            "Epoch 95/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3744060.2500 - accuracy: 0.8063\n",
            "Epoch 96/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -3841922.7500 - accuracy: 0.8063\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -3941471.2500 - accuracy: 0.8063\n",
            "Epoch 98/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4041949.5000 - accuracy: 0.8063\n",
            "Epoch 99/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4144617.5000 - accuracy: 0.8063\n",
            "Epoch 100/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4248039.5000 - accuracy: 0.8063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STgFRQjEXOZY",
        "outputId": "948f9fd0-a02a-4082-820b-2e786d03d577"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 0s - loss: -4.2610e+06 - accuracy: 0.8054 - 370ms/epoch - 16ms/step\n",
            "Loss: -4261005.5, Accuracy: 0.8054421544075012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import checkpoint dependencies\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the checkpoint path and filenames\n",
        "os.makedirs('checkpoints/Optimization1/',exist_ok=True)\n",
        "checkpoint_path = 'checkpoints/Optimization1/weights.{epoch:02d}.hdf5'\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq=100)\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "4G9agXD7FylL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340d1479-7f56-4745-dfeb-f88264966a64"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "69/69 [==============================] - 1s 5ms/step - loss: -4345513.5000 - accuracy: 0.8063\n",
            "Epoch 2/100\n",
            "30/69 [============>.................] - ETA: 0s - loss: -4272081.0000 - accuracy: 0.7937\n",
            "Epoch 2: saving model to checkpoints/Optimization1/weights.02.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4433203.5000 - accuracy: 0.8063\n",
            "Epoch 3/100\n",
            "61/69 [=========================>....] - ETA: 0s - loss: -4507413.0000 - accuracy: 0.8064\n",
            "Epoch 3: saving model to checkpoints/Optimization1/weights.03.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -4522305.0000 - accuracy: 0.8063\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4613027.5000 - accuracy: 0.8063\n",
            "Epoch 5/100\n",
            "19/69 [=======>......................] - ETA: 0s - loss: -4506849.0000 - accuracy: 0.7780\n",
            "Epoch 5: saving model to checkpoints/Optimization1/weights.05.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -4705439.0000 - accuracy: 0.8063\n",
            "Epoch 6/100\n",
            "45/69 [==================>...........] - ETA: 0s - loss: -4850538.0000 - accuracy: 0.8035\n",
            "Epoch 6: saving model to checkpoints/Optimization1/weights.06.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4799571.5000 - accuracy: 0.8063\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4895324.5000 - accuracy: 0.8063\n",
            "Epoch 8/100\n",
            "12/69 [====>.........................] - ETA: 0s - loss: -5037542.0000 - accuracy: 0.8073\n",
            "Epoch 8: saving model to checkpoints/Optimization1/weights.08.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -4992881.0000 - accuracy: 0.8063\n",
            "Epoch 9/100\n",
            "38/69 [===============>..............] - ETA: 0s - loss: -5088591.0000 - accuracy: 0.8158\n",
            "Epoch 9: saving model to checkpoints/Optimization1/weights.09.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -5092399.5000 - accuracy: 0.8063\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -5193546.5000 - accuracy: 0.8063\n",
            "Epoch 11/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -6245953.5000 - accuracy: 0.7188\n",
            "Epoch 11: saving model to checkpoints/Optimization1/weights.11.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -5296526.0000 - accuracy: 0.8063\n",
            "Epoch 12/100\n",
            "32/69 [============>.................] - ETA: 0s - loss: -5300542.0000 - accuracy: 0.8008\n",
            "Epoch 12: saving model to checkpoints/Optimization1/weights.12.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -5401329.0000 - accuracy: 0.8063\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -5507869.5000 - accuracy: 0.8063\n",
            "Epoch 14/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -4106606.0000 - accuracy: 0.8438\n",
            "Epoch 14: saving model to checkpoints/Optimization1/weights.14.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -5616611.0000 - accuracy: 0.8063\n",
            "Epoch 15/100\n",
            "29/69 [===========>..................] - ETA: 0s - loss: -5632469.0000 - accuracy: 0.8179\n",
            "Epoch 15: saving model to checkpoints/Optimization1/weights.15.hdf5\n",
            "69/69 [==============================] - 0s 6ms/step - loss: -5726772.0000 - accuracy: 0.8063\n",
            "Epoch 16/100\n",
            "53/69 [======================>.......] - ETA: 0s - loss: -5806991.0000 - accuracy: 0.8090\n",
            "Epoch 16: saving model to checkpoints/Optimization1/weights.16.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -5839160.0000 - accuracy: 0.8063\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -5953305.0000 - accuracy: 0.8063\n",
            "Epoch 18/100\n",
            "21/69 [========>.....................] - ETA: 0s - loss: -6003691.5000 - accuracy: 0.8170\n",
            "Epoch 18: saving model to checkpoints/Optimization1/weights.18.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -6069183.5000 - accuracy: 0.8063\n",
            "Epoch 19/100\n",
            "57/69 [=======================>......] - ETA: 0s - loss: -6132321.0000 - accuracy: 0.8147\n",
            "Epoch 19: saving model to checkpoints/Optimization1/weights.19.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -6187241.0000 - accuracy: 0.8063\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -6306877.5000 - accuracy: 0.8063\n",
            "Epoch 21/100\n",
            "16/69 [=====>........................] - ETA: 0s - loss: -6593484.5000 - accuracy: 0.8184\n",
            "Epoch 21: saving model to checkpoints/Optimization1/weights.21.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -6428775.0000 - accuracy: 0.8063\n",
            "Epoch 22/100\n",
            "49/69 [====================>.........] - ETA: 0s - loss: -6628861.5000 - accuracy: 0.8106\n",
            "Epoch 22: saving model to checkpoints/Optimization1/weights.22.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -6552308.5000 - accuracy: 0.8063\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -6677996.5000 - accuracy: 0.8063\n",
            "Epoch 24/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -4914146.5000 - accuracy: 0.7500\n",
            "Epoch 24: saving model to checkpoints/Optimization1/weights.24.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -6805901.0000 - accuracy: 0.8063\n",
            "Epoch 25/100\n",
            "40/69 [================>.............] - ETA: 0s - loss: -7001313.5000 - accuracy: 0.8062\n",
            "Epoch 25: saving model to checkpoints/Optimization1/weights.25.hdf5\n",
            "69/69 [==============================] - 1s 8ms/step - loss: -6935492.0000 - accuracy: 0.8063\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 1s 8ms/step - loss: -7067054.5000 - accuracy: 0.8063\n",
            "Epoch 27/100\n",
            " 1/69 [..............................] - ETA: 1s - loss: -5963894.0000 - accuracy: 0.7812\n",
            "Epoch 27: saving model to checkpoints/Optimization1/weights.27.hdf5\n",
            "69/69 [==============================] - 0s 6ms/step - loss: -7200684.5000 - accuracy: 0.8063\n",
            "Epoch 28/100\n",
            "33/69 [=============>................] - ETA: 0s - loss: -7307247.0000 - accuracy: 0.8163\n",
            "Epoch 28: saving model to checkpoints/Optimization1/weights.28.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -7336345.5000 - accuracy: 0.8063\n",
            "Epoch 29/100\n",
            "63/69 [==========================>...] - ETA: 0s - loss: -7467223.5000 - accuracy: 0.8036\n",
            "Epoch 29: saving model to checkpoints/Optimization1/weights.29.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -7473591.0000 - accuracy: 0.8063\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -7612994.5000 - accuracy: 0.8063\n",
            "Epoch 31/100\n",
            "25/69 [=========>....................] - ETA: 0s - loss: -8088344.5000 - accuracy: 0.8075\n",
            "Epoch 31: saving model to checkpoints/Optimization1/weights.31.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -7754079.0000 - accuracy: 0.8063\n",
            "Epoch 32/100\n",
            "54/69 [======================>.......] - ETA: 0s - loss: -7789079.0000 - accuracy: 0.8009\n",
            "Epoch 32: saving model to checkpoints/Optimization1/weights.32.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -7897845.0000 - accuracy: 0.8063\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -8042963.0000 - accuracy: 0.8063\n",
            "Epoch 34/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -10314024.0000 - accuracy: 0.8125\n",
            "Epoch 34: saving model to checkpoints/Optimization1/weights.34.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -8190374.5000 - accuracy: 0.8063\n",
            "Epoch 35/100\n",
            "49/69 [====================>.........] - ETA: 0s - loss: -8392767.0000 - accuracy: 0.7991\n",
            "Epoch 35: saving model to checkpoints/Optimization1/weights.35.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -8339472.5000 - accuracy: 0.8063\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -8490985.0000 - accuracy: 0.8063\n",
            "Epoch 37/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -10646432.0000 - accuracy: 0.9062\n",
            "Epoch 37: saving model to checkpoints/Optimization1/weights.37.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -8644175.0000 - accuracy: 0.8063\n",
            "Epoch 38/100\n",
            "43/69 [=================>............] - ETA: 0s - loss: -8668092.0000 - accuracy: 0.8009\n",
            "Epoch 38: saving model to checkpoints/Optimization1/weights.38.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -8799323.0000 - accuracy: 0.8063\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -8956324.0000 - accuracy: 0.8063\n",
            "Epoch 40/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -5962115.5000 - accuracy: 0.8750\n",
            "Epoch 40: saving model to checkpoints/Optimization1/weights.40.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -9115518.0000 - accuracy: 0.8063\n",
            "Epoch 41/100\n",
            "25/69 [=========>....................] - ETA: 0s - loss: -8970857.0000 - accuracy: 0.8025\n",
            "Epoch 41: saving model to checkpoints/Optimization1/weights.41.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -9276880.0000 - accuracy: 0.8063\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -9440095.0000 - accuracy: 0.8063\n",
            "Epoch 43/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -10583011.0000 - accuracy: 0.8750\n",
            "Epoch 43: saving model to checkpoints/Optimization1/weights.43.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -9605382.0000 - accuracy: 0.8063\n",
            "Epoch 44/100\n",
            "23/69 [=========>....................] - ETA: 0s - loss: -9995747.0000 - accuracy: 0.8315\n",
            "Epoch 44: saving model to checkpoints/Optimization1/weights.44.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -9772494.0000 - accuracy: 0.8063\n",
            "Epoch 45/100\n",
            "51/69 [=====================>........] - ETA: 0s - loss: -9818769.0000 - accuracy: 0.8082\n",
            "Epoch 45: saving model to checkpoints/Optimization1/weights.45.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -9942193.0000 - accuracy: 0.8063\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -10113005.0000 - accuracy: 0.8063\n",
            "Epoch 47/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -11751456.0000 - accuracy: 0.8438\n",
            "Epoch 47: saving model to checkpoints/Optimization1/weights.47.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -10286453.0000 - accuracy: 0.8063\n",
            "Epoch 48/100\n",
            "45/69 [==================>...........] - ETA: 0s - loss: -10242888.0000 - accuracy: 0.8090\n",
            "Epoch 48: saving model to checkpoints/Optimization1/weights.48.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -10462003.0000 - accuracy: 0.8063\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -10639249.0000 - accuracy: 0.8063\n",
            "Epoch 50/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -11573136.0000 - accuracy: 0.8750\n",
            "Epoch 50: saving model to checkpoints/Optimization1/weights.50.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -10818702.0000 - accuracy: 0.8063\n",
            "Epoch 51/100\n",
            "27/69 [==========>...................] - ETA: 0s - loss: -10955239.0000 - accuracy: 0.7870\n",
            "Epoch 51: saving model to checkpoints/Optimization1/weights.51.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -11000573.0000 - accuracy: 0.8063\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -11183613.0000 - accuracy: 0.8063\n",
            "Epoch 53/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -8388333.5000 - accuracy: 0.8438\n",
            "Epoch 53: saving model to checkpoints/Optimization1/weights.53.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -11369817.0000 - accuracy: 0.8063\n",
            "Epoch 54/100\n",
            "27/69 [==========>...................] - ETA: 0s - loss: -11393261.0000 - accuracy: 0.8183\n",
            "Epoch 54: saving model to checkpoints/Optimization1/weights.54.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -11557251.0000 - accuracy: 0.8063\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -11746891.0000 - accuracy: 0.8063\n",
            "Epoch 56/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -12778460.0000 - accuracy: 0.7500\n",
            "Epoch 56: saving model to checkpoints/Optimization1/weights.56.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -11938726.0000 - accuracy: 0.8063\n",
            "Epoch 57/100\n",
            "31/69 [============>.................] - ETA: 0s - loss: -12398638.0000 - accuracy: 0.7933\n",
            "Epoch 57: saving model to checkpoints/Optimization1/weights.57.hdf5\n",
            "69/69 [==============================] - 0s 6ms/step - loss: -12132438.0000 - accuracy: 0.8063\n",
            "Epoch 58/100\n",
            "60/69 [=========================>....] - ETA: 0s - loss: -12253218.0000 - accuracy: 0.8052\n",
            "Epoch 58: saving model to checkpoints/Optimization1/weights.58.hdf5\n",
            "69/69 [==============================] - 0s 6ms/step - loss: -12328248.0000 - accuracy: 0.8063\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: -12525969.0000 - accuracy: 0.8063\n",
            "Epoch 60/100\n",
            "25/69 [=========>....................] - ETA: 0s - loss: -12895613.0000 - accuracy: 0.8100\n",
            "Epoch 60: saving model to checkpoints/Optimization1/weights.60.hdf5\n",
            "69/69 [==============================] - 0s 5ms/step - loss: -12725760.0000 - accuracy: 0.8063\n",
            "Epoch 61/100\n",
            "59/69 [========================>.....] - ETA: 0s - loss: -12751323.0000 - accuracy: 0.8035\n",
            "Epoch 61: saving model to checkpoints/Optimization1/weights.61.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -12927799.0000 - accuracy: 0.8063\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -13131190.0000 - accuracy: 0.8063\n",
            "Epoch 63/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -13819088.0000 - accuracy: 0.8438\n",
            "Epoch 63: saving model to checkpoints/Optimization1/weights.63.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -13337248.0000 - accuracy: 0.8063\n",
            "Epoch 64/100\n",
            "47/69 [===================>..........] - ETA: 0s - loss: -13686779.0000 - accuracy: 0.8039\n",
            "Epoch 64: saving model to checkpoints/Optimization1/weights.64.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -13545504.0000 - accuracy: 0.8063\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -13755522.0000 - accuracy: 0.8063\n",
            "Epoch 66/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -15219141.0000 - accuracy: 0.6562\n",
            "Epoch 66: saving model to checkpoints/Optimization1/weights.66.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -13968208.0000 - accuracy: 0.8063\n",
            "Epoch 67/100\n",
            "42/69 [=================>............] - ETA: 0s - loss: -14054057.0000 - accuracy: 0.8177\n",
            "Epoch 67: saving model to checkpoints/Optimization1/weights.67.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -14182644.0000 - accuracy: 0.8063\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -14399131.0000 - accuracy: 0.8063\n",
            "Epoch 69/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -12487778.0000 - accuracy: 0.8125\n",
            "Epoch 69: saving model to checkpoints/Optimization1/weights.69.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -14618350.0000 - accuracy: 0.8063\n",
            "Epoch 70/100\n",
            "27/69 [==========>...................] - ETA: 0s - loss: -14884056.0000 - accuracy: 0.8148\n",
            "Epoch 70: saving model to checkpoints/Optimization1/weights.70.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -14839102.0000 - accuracy: 0.8063\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -15062733.0000 - accuracy: 0.8063\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 72: saving model to checkpoints/Optimization1/weights.72.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -15287832.0000 - accuracy: 0.8063\n",
            "Epoch 73/100\n",
            "24/69 [=========>....................] - ETA: 0s - loss: -15657960.0000 - accuracy: 0.8008\n",
            "Epoch 73: saving model to checkpoints/Optimization1/weights.73.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -15514920.0000 - accuracy: 0.8063\n",
            "Epoch 74/100\n",
            "47/69 [===================>..........] - ETA: 0s - loss: -15804713.0000 - accuracy: 0.8052\n",
            "Epoch 74: saving model to checkpoints/Optimization1/weights.74.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -15744955.0000 - accuracy: 0.8063\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -15976588.0000 - accuracy: 0.8063\n",
            "Epoch 76/100\n",
            "22/69 [========>.....................] - ETA: 0s - loss: -16830546.0000 - accuracy: 0.8224\n",
            "Epoch 76: saving model to checkpoints/Optimization1/weights.76.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -16210575.0000 - accuracy: 0.8063\n",
            "Epoch 77/100\n",
            "51/69 [=====================>........] - ETA: 0s - loss: -16212099.0000 - accuracy: 0.8027\n",
            "Epoch 77: saving model to checkpoints/Optimization1/weights.77.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -16446477.0000 - accuracy: 0.8063\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -16684641.0000 - accuracy: 0.8063\n",
            "Epoch 79/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -12066256.0000 - accuracy: 0.9062\n",
            "Epoch 79: saving model to checkpoints/Optimization1/weights.79.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -16924894.0000 - accuracy: 0.8063\n",
            "Epoch 80/100\n",
            "25/69 [=========>....................] - ETA: 0s - loss: -17447000.0000 - accuracy: 0.8075\n",
            "Epoch 80: saving model to checkpoints/Optimization1/weights.80.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -17167464.0000 - accuracy: 0.8063\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -17412010.0000 - accuracy: 0.8063\n",
            "Epoch 82/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -17173390.0000 - accuracy: 0.9375\n",
            "Epoch 82: saving model to checkpoints/Optimization1/weights.82.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -17658882.0000 - accuracy: 0.8063\n",
            "Epoch 83/100\n",
            "38/69 [===============>..............] - ETA: 0s - loss: -17551418.0000 - accuracy: 0.8051\n",
            "Epoch 83: saving model to checkpoints/Optimization1/weights.83.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -17907658.0000 - accuracy: 0.8063\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -18158362.0000 - accuracy: 0.8063\n",
            "Epoch 85/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -23290946.0000 - accuracy: 0.7500\n",
            "Epoch 85: saving model to checkpoints/Optimization1/weights.85.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -18412442.0000 - accuracy: 0.8063\n",
            "Epoch 86/100\n",
            "23/69 [=========>....................] - ETA: 0s - loss: -18268534.0000 - accuracy: 0.7894\n",
            "Epoch 86: saving model to checkpoints/Optimization1/weights.86.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -18667378.0000 - accuracy: 0.8063\n",
            "Epoch 87/100\n",
            "51/69 [=====================>........] - ETA: 0s - loss: -18938710.0000 - accuracy: 0.8082\n",
            "Epoch 87: saving model to checkpoints/Optimization1/weights.87.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -18925334.0000 - accuracy: 0.8063\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -19185296.0000 - accuracy: 0.8063\n",
            "Epoch 89/100\n",
            "25/69 [=========>....................] - ETA: 0s - loss: -19762580.0000 - accuracy: 0.8087\n",
            "Epoch 89: saving model to checkpoints/Optimization1/weights.89.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -19447888.0000 - accuracy: 0.8063\n",
            "Epoch 90/100\n",
            "47/69 [===================>..........] - ETA: 0s - loss: -19496446.0000 - accuracy: 0.8098\n",
            "Epoch 90: saving model to checkpoints/Optimization1/weights.90.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -19712734.0000 - accuracy: 0.8063\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -19979656.0000 - accuracy: 0.8063\n",
            "Epoch 92/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -18238168.0000 - accuracy: 0.7812\n",
            "Epoch 92: saving model to checkpoints/Optimization1/weights.92.hdf5\n",
            "69/69 [==============================] - 0s 4ms/step - loss: -20248642.0000 - accuracy: 0.8063\n",
            "Epoch 93/100\n",
            "45/69 [==================>...........] - ETA: 0s - loss: -19975654.0000 - accuracy: 0.8090\n",
            "Epoch 93: saving model to checkpoints/Optimization1/weights.93.hdf5\n",
            "69/69 [==============================] - 0s 7ms/step - loss: -20520816.0000 - accuracy: 0.8063\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -20794048.0000 - accuracy: 0.8063\n",
            "Epoch 95/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -24832328.0000 - accuracy: 0.9375\n",
            "Epoch 95: saving model to checkpoints/Optimization1/weights.95.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -21070464.0000 - accuracy: 0.8063\n",
            "Epoch 96/100\n",
            "38/69 [===============>..............] - ETA: 0s - loss: -21508440.0000 - accuracy: 0.8051\n",
            "Epoch 96: saving model to checkpoints/Optimization1/weights.96.hdf5\n",
            "69/69 [==============================] - 1s 8ms/step - loss: -21348734.0000 - accuracy: 0.8063\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -21629384.0000 - accuracy: 0.8063\n",
            "Epoch 98/100\n",
            " 1/69 [..............................] - ETA: 0s - loss: -24228336.0000 - accuracy: 0.9688\n",
            "Epoch 98: saving model to checkpoints/Optimization1/weights.98.hdf5\n",
            "69/69 [==============================] - 0s 3ms/step - loss: -21912800.0000 - accuracy: 0.8063\n",
            "Epoch 99/100\n",
            "26/69 [==========>...................] - ETA: 0s - loss: -23133400.0000 - accuracy: 0.8293\n",
            "Epoch 99: saving model to checkpoints/Optimization1/weights.99.hdf5\n",
            "69/69 [==============================] - 0s 2ms/step - loss: -22197428.0000 - accuracy: 0.8063\n",
            "Epoch 100/100\n",
            "65/69 [===========================>..] - ETA: 0s - loss: -22396272.0000 - accuracy: 0.8038\n",
            "Epoch 100: saving model to checkpoints/Optimization1/weights.100.hdf5\n",
            "69/69 [==============================] - 1s 7ms/step - loss: -22485486.0000 - accuracy: 0.8063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5_POsgaaWB_",
        "outputId": "99b0bb46-8f15-4629-fa9e-8d527a36e5c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 0s - loss: -2.2430e+07 - accuracy: 0.8054 - 162ms/epoch - 7ms/step\n",
            "Loss: -22429520.0, Accuracy: 0.8054421544075012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('groupprojectMachineLearning_model')\n"
      ],
      "metadata": {
        "id": "GyAoR4RHaWcW"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}