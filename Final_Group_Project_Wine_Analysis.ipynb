{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sethi-rasna/Wine_Os/blob/main/MACHINE_LEARNING_final_group_project_MACHINE_LEARNING_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "ga1j0QycZrUC",
    "outputId": "ab3596ae-a8f5-42ac-84fa-930d0d971e99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_type</th>\n",
       "      <th>winetype_numeric</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>fixed acidity.1</th>\n",
       "      <th>sulphates 1=low 2=high</th>\n",
       "      <th>alcohol 1=low 2=high</th>\n",
       "      <th>fixed acidity 1=low 2=high</th>\n",
       "      <th>healthiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.045</td>\n",
       "      <td>41.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.092</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.99647</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.086</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.99464</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.99464</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.069</td>\n",
       "      <td>26.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.99358</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wine_type  winetype_numeric  fixed acidity  volatile acidity  citric acid  \\\n",
       "0       red                 1            5.0              1.02         0.04   \n",
       "1       red                 1            6.0              0.50         0.04   \n",
       "2       red                 1            6.1              0.32         0.25   \n",
       "3       red                 1            6.1              0.34         0.25   \n",
       "4       red                 1            6.1              0.64         0.02   \n",
       "\n",
       "   residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "0             1.4      0.045                 41.0                  85.0   \n",
       "1             2.2      0.092                 13.0                  26.0   \n",
       "2             1.8      0.086                  5.0                  32.0   \n",
       "3             1.8      0.084                  4.0                  28.0   \n",
       "4             2.4      0.069                 26.0                  46.0   \n",
       "\n",
       "   density    pH  sulphates  alcohol  fixed acidity.1  sulphates 1=low 2=high  \\\n",
       "0  0.99380  3.75       0.48     10.5              5.0                       1   \n",
       "1  0.99647  3.46       0.47     10.0              6.0                       1   \n",
       "2  0.99464  3.36       0.44     10.1              6.1                       1   \n",
       "3  0.99464  3.36       0.44     10.1              6.1                       1   \n",
       "4  0.99358  3.47       0.45     11.0              6.1                       1   \n",
       "\n",
       "   alcohol 1=low 2=high  fixed acidity 1=low 2=high  healthiness  quality  \n",
       "0                     2                           1            1        2  \n",
       "1                     2                           1            1        2  \n",
       "2                     2                           1            1        2  \n",
       "3                     2                           1            1        2  \n",
       "4                     2                           1            1        2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Import our input dataset\n",
    "application_df = pd.read_csv('resources/red_white.csv')\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!What is your password········\n"
     ]
    }
   ],
   "source": [
    "# Load the raw data to pgAdmin database\n",
    "# Store environmental variable\n",
    "from getpass import getpass\n",
    "password = getpass('!What is your password')\n",
    "# Configure settings for RDS\n",
    "mode = \"append\"\n",
    "jdbc_url=\"jdbc:postgresql://Red_White_Wine/postgres@PostgreSQL 14\"\n",
    "config = {\"user\":\"postgres\",\n",
    "          \"password\": password,\n",
    "          \"driver\":\"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'postgres'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36000\\128295842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m conn = ps.connect(\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"postgres\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"5432\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdbname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Red_White_Wine\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;31m# raise KeyError with the original key value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'postgres'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2 as ps\n",
    "conn = ps.connect(\n",
    "    host=os.environ[\"postgres\"],\n",
    "    port=os.environ[\"5432\"],\n",
    "    dbname=os.environ[\"Red_White_Wine\"],\n",
    "    user=os.environ[\"postgres\"],\n",
    "    password=os.environ[\"!Hebob77\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XA0e7dE6aowK"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "ICLEv9w2WMHh",
    "outputId": "df9ea38b-df47-4084-a161-a8f0fecf66c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethi\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winetype_numeric</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>fixed acidity.1</th>\n",
       "      <th>sulphates 1=low 2=high</th>\n",
       "      <th>alcohol 1=low 2=high</th>\n",
       "      <th>fixed acidity 1=low 2=high</th>\n",
       "      <th>healthiness</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.99647</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.99464</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.99464</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.99358</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.99488</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.46</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.99220</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>12.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.49</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.99396</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winetype_numeric  fixed acidity  residual sugar  density    pH  sulphates  \\\n",
       "0                 1            5.0             1.4  0.99380  3.75       0.48   \n",
       "1                 1            6.0             2.2  0.99647  3.46       0.47   \n",
       "2                 1            6.1             1.8  0.99464  3.36       0.44   \n",
       "3                 1            6.1             1.8  0.99464  3.36       0.44   \n",
       "4                 1            6.1             2.4  0.99358  3.47       0.45   \n",
       "5                 1            6.3             2.0  0.99488  3.60       0.46   \n",
       "6                 1            6.3             1.4  0.99220  3.45       0.48   \n",
       "7                 1            6.4             2.1  0.99490  3.49       0.49   \n",
       "8                 1            6.4             3.2  0.99500  3.61       0.49   \n",
       "9                 1            6.6             1.6  0.99396  3.33       0.37   \n",
       "\n",
       "   alcohol  fixed acidity.1  sulphates 1=low 2=high  alcohol 1=low 2=high  \\\n",
       "0     10.5              5.0                       1                     2   \n",
       "1     10.0              6.0                       1                     2   \n",
       "2     10.1              6.1                       1                     2   \n",
       "3     10.1              6.1                       1                     2   \n",
       "4     11.0              6.1                       1                     2   \n",
       "5     11.2              6.3                       1                     2   \n",
       "6     12.3              6.3                       1                     2   \n",
       "7     11.4              6.4                       1                     2   \n",
       "8     12.7              6.4                       1                     2   \n",
       "9     10.4              6.6                       1                     2   \n",
       "\n",
       "   fixed acidity 1=low 2=high  healthiness  quality  \n",
       "0                           1            1        2  \n",
       "1                           1            1        2  \n",
       "2                           1            1        2  \n",
       "3                           1            1        2  \n",
       "4                           1            1        2  \n",
       "5                           1            1        2  \n",
       "6                           1            1        2  \n",
       "7                           1            1        2  \n",
       "8                           1            1        2  \n",
       "9                           1            1        2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the non-beneficial ID columns, 'volatile acidity','citric acid', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide'.\n",
    "application_df = application_df.drop(['wine_type','volatile acidity','citric acid', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide'],1)\n",
    "application_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfTKCZ7uvlAF",
    "outputId": "9b4e50f5-17b3-478a-a94f-9981ee99c03e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winetype_numeric                2\n",
       "fixed acidity                 102\n",
       "residual sugar                254\n",
       "density                       752\n",
       "pH                             98\n",
       "sulphates                     108\n",
       "alcohol                        84\n",
       "fixed acidity.1               102\n",
       "sulphates 1=low 2=high          2\n",
       "alcohol 1=low 2=high            2\n",
       "fixed acidity 1=low 2=high      2\n",
       "healthiness                     2\n",
       "quality                         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Cpchu9PyDPk",
    "outputId": "c56aa2ce-b8d8-4c5b-debc-7e4f9bd9f2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1470\n",
       "2    1470\n",
       "Name: winetype_numeric, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at winetype_numeric value counts for binning\n",
    "application_count = application_df.winetype_numeric.value_counts()\n",
    "application_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IUTzNsJF2PRe"
   },
   "outputs": [],
   "source": [
    "# Generate our categorical variable lists \n",
    "#application_cat = application_df.dtypes[application_df.dtypes == 'object'].index.tolist()\n",
    "#application_df[application_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ny4_AbQPEk9X",
    "outputId": "c6dcdc09-633e-4d99-fe70-03d330edcc70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethi\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# define \"healthy\" column with metrics scores based on sulphate content. IF low then 1= HEALTHY If high then 2= NOT HEALTHY \n",
    "\n",
    "y = application_df[['healthiness','quality']].values\n",
    "X = application_df.drop(['healthiness','quality'],1).values \n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UFKLCusBjjNR"
   },
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Bn0kGsGXM4Y",
    "outputId": "592604ad-40ef-49c6-e2c2-96734d893641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                960       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 62        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,452\n",
      "Trainable params: 3,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1,input_dim=number_input_features,activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2,activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(Dense(units=2,activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8C2sR4eqXNTy"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ls4p61IXNmH",
    "outputId": "c254191c-dada-4b30-e43f-e1eebaec4e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 3s 7ms/step - loss: -1.1641 - accuracy: 0.3887\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -14.8764 - accuracy: 0.2553\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -77.2996 - accuracy: 0.1937\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -251.1166 - accuracy: 0.1937\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -599.8790 - accuracy: 0.1937\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -1182.6370 - accuracy: 0.1937\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -2053.6960 - accuracy: 0.1937\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3260.8010 - accuracy: 0.1937\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -4838.9111 - accuracy: 0.1937\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -6818.3218 - accuracy: 0.1937\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -9251.5449 - accuracy: 0.1937\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -12174.6289 - accuracy: 0.1937\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -15600.6748 - accuracy: 0.1937\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 1s 7ms/step - loss: -19588.5254 - accuracy: 0.1937\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -24129.0527 - accuracy: 0.1937\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -29271.2402 - accuracy: 0.1937\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -35014.8047 - accuracy: 0.1937\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -41475.8906 - accuracy: 0.1937\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -48628.0586 - accuracy: 0.1937\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: -56501.2734 - accuracy: 0.1937\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 1s 9ms/step - loss: -65121.0156 - accuracy: 0.1937\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -74497.9062 - accuracy: 0.1937\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 1s 8ms/step - loss: -84751.8828 - accuracy: 0.1937\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -95818.3750 - accuracy: 0.1937\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 1s 13ms/step - loss: -107734.0781 - accuracy: 0.1937\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 1s 7ms/step - loss: -120485.5547 - accuracy: 0.1937\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 1s 13ms/step - loss: -134098.2969 - accuracy: 0.1937\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: -148530.1719 - accuracy: 0.1937\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: -163845.8750 - accuracy: 0.1937\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 1s 8ms/step - loss: -180066.8594 - accuracy: 0.1937\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: -197189.3750 - accuracy: 0.1937\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 1s 10ms/step - loss: -215196.6250 - accuracy: 0.1937\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 1s 9ms/step - loss: -234174.0156 - accuracy: 0.1937\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 1s 8ms/step - loss: -254179.2656 - accuracy: 0.1937\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 1s 9ms/step - loss: -275282.9062 - accuracy: 0.1937\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -297401.0625 - accuracy: 0.1937\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -320451.3125 - accuracy: 0.1937\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -344641.1562 - accuracy: 0.1937\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -369733.0938 - accuracy: 0.1937\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -395865.0625 - accuracy: 0.1937\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -423076.9375 - accuracy: 0.1937\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -451198.4062 - accuracy: 0.1937\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -480404.0938 - accuracy: 0.1937\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -510645.1250 - accuracy: 0.1937\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -542006.0625 - accuracy: 0.1937\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -574382.9375 - accuracy: 0.1937\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -607945.8125 - accuracy: 0.1937\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -642503.3750 - accuracy: 0.1937\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -678205.5625 - accuracy: 0.1937\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -714945.1875 - accuracy: 0.1937\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -752834.7500 - accuracy: 0.1937\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -791798.3750 - accuracy: 0.1937\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -831792.2500 - accuracy: 0.1937\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -872983.3125 - accuracy: 0.1937\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -915361.3125 - accuracy: 0.1937\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -958771.6875 - accuracy: 0.1937\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -1003395.7500 - accuracy: 0.1937\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -1049222.5000 - accuracy: 0.1937\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -1096173.1250 - accuracy: 0.1937\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -1144362.7500 - accuracy: 0.1937\n",
      "Epoch 61/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -1193788.6250 - accuracy: 0.1937\n",
      "Epoch 62/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -1244224.1250 - accuracy: 0.1937\n",
      "Epoch 63/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -1295974.1250 - accuracy: 0.1937\n",
      "Epoch 64/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -1348831.1250 - accuracy: 0.1937\n",
      "Epoch 65/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -1403021.8750 - accuracy: 0.1937\n",
      "Epoch 66/100\n",
      "69/69 [==============================] - 1s 7ms/step - loss: -1458377.5000 - accuracy: 0.1937\n",
      "Epoch 67/100\n",
      "69/69 [==============================] - 1s 10ms/step - loss: -1515028.6250 - accuracy: 0.1937\n",
      "Epoch 68/100\n",
      "69/69 [==============================] - 1s 9ms/step - loss: -1572785.7500 - accuracy: 0.1937\n",
      "Epoch 69/100\n",
      "69/69 [==============================] - 1s 10ms/step - loss: -1631997.8750 - accuracy: 0.1937\n",
      "Epoch 70/100\n",
      "69/69 [==============================] - 1s 9ms/step - loss: -1692248.3750 - accuracy: 0.1937\n",
      "Epoch 71/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -1753826.8750 - accuracy: 0.1937\n",
      "Epoch 72/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -1816741.0000 - accuracy: 0.1937\n",
      "Epoch 73/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -1880720.0000 - accuracy: 0.1937\n",
      "Epoch 74/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -1946158.5000 - accuracy: 0.1937\n",
      "Epoch 75/100\n",
      "69/69 [==============================] - 1s 9ms/step - loss: -2012698.7500 - accuracy: 0.1937\n",
      "Epoch 76/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -2080498.0000 - accuracy: 0.1937\n",
      "Epoch 77/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -2149865.5000 - accuracy: 0.1937\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 6ms/step - loss: -2220217.7500 - accuracy: 0.1937\n",
      "Epoch 79/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -2292018.0000 - accuracy: 0.1937\n",
      "Epoch 80/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -2365354.7500 - accuracy: 0.1937\n",
      "Epoch 81/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -2439889.2500 - accuracy: 0.1937\n",
      "Epoch 82/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -2515960.7500 - accuracy: 0.1937\n",
      "Epoch 83/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -2593156.7500 - accuracy: 0.1937\n",
      "Epoch 84/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -2672046.5000 - accuracy: 0.1937\n",
      "Epoch 85/100\n",
      "69/69 [==============================] - 0s 7ms/step - loss: -2752137.0000 - accuracy: 0.1937\n",
      "Epoch 86/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -2833710.0000 - accuracy: 0.1937\n",
      "Epoch 87/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -2916756.2500 - accuracy: 0.1937\n",
      "Epoch 88/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3001136.2500 - accuracy: 0.1937\n",
      "Epoch 89/100\n",
      "69/69 [==============================] - 0s 5ms/step - loss: -3086952.0000 - accuracy: 0.1937\n",
      "Epoch 90/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3174253.0000 - accuracy: 0.1937\n",
      "Epoch 91/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3262772.5000 - accuracy: 0.1937\n",
      "Epoch 92/100\n",
      "69/69 [==============================] - 1s 7ms/step - loss: -3353081.2500 - accuracy: 0.1937\n",
      "Epoch 93/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3444546.2500 - accuracy: 0.1937\n",
      "Epoch 94/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3537607.2500 - accuracy: 0.1937\n",
      "Epoch 95/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3631936.5000 - accuracy: 0.1937\n",
      "Epoch 96/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3728087.2500 - accuracy: 0.1937\n",
      "Epoch 97/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3825327.5000 - accuracy: 0.1937\n",
      "Epoch 98/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -3924315.0000 - accuracy: 0.1937\n",
      "Epoch 99/100\n",
      "69/69 [==============================] - 1s 7ms/step - loss: -4024679.0000 - accuracy: 0.1937\n",
      "Epoch 100/100\n",
      "69/69 [==============================] - 0s 6ms/step - loss: -4126649.0000 - accuracy: 0.1937\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STgFRQjEXOZY",
    "outputId": "0dfb6e02-effb-46b2-c456-8a0893548a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 0s - loss: -4.1752e+06 - accuracy: 0.8054 - 148ms/epoch - 6ms/step\n",
      "Loss: -4175249.25, Accuracy: 0.8054421544075012\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z22smeqbIUWj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4G9agXD7FylL",
    "outputId": "01e4bbbd-51b7-43fd-d13a-fd101bc13fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -4258695.0000 - accuracy: 0.8063\n",
      "Epoch 2/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -3622044.0000 - accuracy: 0.8438\n",
      "Epoch 2: saving model to checkpoints/Optimization1/weights.02.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -4343075.0000 - accuracy: 0.8063\n",
      "Epoch 3/100\n",
      "35/69 [==============>...............] - ETA: 0s - loss: -4353378.0000 - accuracy: 0.8107\n",
      "Epoch 3: saving model to checkpoints/Optimization1/weights.03.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -4430429.0000 - accuracy: 0.8063\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -4519290.0000 - accuracy: 0.8063\n",
      "Epoch 5/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -3445044.0000 - accuracy: 0.7812\n",
      "Epoch 5: saving model to checkpoints/Optimization1/weights.05.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -4610162.0000 - accuracy: 0.8063\n",
      "Epoch 6/100\n",
      "41/69 [================>.............] - ETA: 0s - loss: -4744763.0000 - accuracy: 0.7980\n",
      "Epoch 6: saving model to checkpoints/Optimization1/weights.06.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -4702892.0000 - accuracy: 0.8063\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -4797510.0000 - accuracy: 0.8063\n",
      "Epoch 8/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -5553032.0000 - accuracy: 0.8438\n",
      "Epoch 8: saving model to checkpoints/Optimization1/weights.08.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -4893958.5000 - accuracy: 0.8063\n",
      "Epoch 9/100\n",
      "41/69 [================>.............] - ETA: 0s - loss: -4963233.0000 - accuracy: 0.8117\n",
      "Epoch 9: saving model to checkpoints/Optimization1/weights.09.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -4992408.0000 - accuracy: 0.8063\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -5092258.0000 - accuracy: 0.8063\n",
      "Epoch 11/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -6269196.0000 - accuracy: 0.8750\n",
      "Epoch 11: saving model to checkpoints/Optimization1/weights.11.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -5194161.5000 - accuracy: 0.8063\n",
      "Epoch 12/100\n",
      "33/69 [=============>................] - ETA: 0s - loss: -5131410.0000 - accuracy: 0.8229\n",
      "Epoch 12: saving model to checkpoints/Optimization1/weights.12.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -5297723.0000 - accuracy: 0.8063\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -5403060.5000 - accuracy: 0.8063\n",
      "Epoch 14/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -6403408.0000 - accuracy: 0.8750\n",
      "Epoch 14: saving model to checkpoints/Optimization1/weights.14.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -5510512.5000 - accuracy: 0.8063\n",
      "Epoch 15/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -8094447.0000 - accuracy: 0.9688\n",
      "Epoch 15: saving model to checkpoints/Optimization1/weights.15.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -5619589.0000 - accuracy: 0.8063\n",
      "Epoch 16/100\n",
      "42/69 [=================>............] - ETA: 0s - loss: -5584160.0000 - accuracy: 0.8043\n",
      "Epoch 16: saving model to checkpoints/Optimization1/weights.16.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -5730902.0000 - accuracy: 0.8063\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -5843554.0000 - accuracy: 0.8063\n",
      "Epoch 18/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -6646345.0000 - accuracy: 0.8438\n",
      "Epoch 18: saving model to checkpoints/Optimization1/weights.18.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -5958986.5000 - accuracy: 0.8063\n",
      "Epoch 19/100\n",
      "40/69 [================>.............] - ETA: 0s - loss: -6157314.5000 - accuracy: 0.8039\n",
      "Epoch 19: saving model to checkpoints/Optimization1/weights.19.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -6075484.5000 - accuracy: 0.8063\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -6194453.0000 - accuracy: 0.8063\n",
      "Epoch 21/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -5618918.0000 - accuracy: 0.8438\n",
      "Epoch 21: saving model to checkpoints/Optimization1/weights.21.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -6315109.0000 - accuracy: 0.8063\n",
      "Epoch 22/100\n",
      "46/69 [===================>..........] - ETA: 0s - loss: -6185422.5000 - accuracy: 0.7894\n",
      "Epoch 22: saving model to checkpoints/Optimization1/weights.22.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -6437804.0000 - accuracy: 0.8063\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -6562300.5000 - accuracy: 0.8063\n",
      "Epoch 24/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -4439669.0000 - accuracy: 0.8750\n",
      "Epoch 24: saving model to checkpoints/Optimization1/weights.24.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -6688716.5000 - accuracy: 0.8063\n",
      "Epoch 25/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -5008933.5000 - accuracy: 0.8438\n",
      "Epoch 25: saving model to checkpoints/Optimization1/weights.25.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -6817096.0000 - accuracy: 0.8063\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -6947467.5000 - accuracy: 0.8063\n",
      "Epoch 27/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -5878468.0000 - accuracy: 0.8750\n",
      "Epoch 27: saving model to checkpoints/Optimization1/weights.27.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -7079761.0000 - accuracy: 0.8063\n",
      "Epoch 28/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -7610115.0000 - accuracy: 0.7500\n",
      "Epoch 28: saving model to checkpoints/Optimization1/weights.28.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -7213775.0000 - accuracy: 0.8063\n",
      "Epoch 29/100\n",
      "38/69 [===============>..............] - ETA: 0s - loss: -7151124.0000 - accuracy: 0.7985\n",
      "Epoch 29: saving model to checkpoints/Optimization1/weights.29.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -7350104.0000 - accuracy: 0.8063\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -7487650.0000 - accuracy: 0.8063\n",
      "Epoch 31/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -9604343.0000 - accuracy: 0.7188\n",
      "Epoch 31: saving model to checkpoints/Optimization1/weights.31.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -7628010.0000 - accuracy: 0.8063\n",
      "Epoch 32/100\n",
      "45/69 [==================>...........] - ETA: 0s - loss: -7874172.5000 - accuracy: 0.8090\n",
      "Epoch 32: saving model to checkpoints/Optimization1/weights.32.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -7769986.5000 - accuracy: 0.8063\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -7914063.5000 - accuracy: 0.8063\n",
      "Epoch 34/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -10703990.0000 - accuracy: 0.7812\n",
      "Epoch 34: saving model to checkpoints/Optimization1/weights.34.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -8059956.5000 - accuracy: 0.8063\n",
      "Epoch 35/100\n",
      "42/69 [=================>............] - ETA: 0s - loss: -8172488.5000 - accuracy: 0.8065\n",
      "Epoch 35: saving model to checkpoints/Optimization1/weights.35.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -8207958.5000 - accuracy: 0.8063\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -8357684.5000 - accuracy: 0.8063\n",
      "Epoch 37/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -8108211.0000 - accuracy: 0.8438\n",
      "Epoch 37: saving model to checkpoints/Optimization1/weights.37.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -8509468.0000 - accuracy: 0.8063\n",
      "Epoch 38/100\n",
      "36/69 [==============>...............] - ETA: 0s - loss: -8756060.0000 - accuracy: 0.8073\n",
      "Epoch 38: saving model to checkpoints/Optimization1/weights.38.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -8663375.0000 - accuracy: 0.8063\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -8818963.0000 - accuracy: 0.8063\n",
      "Epoch 40/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -6882612.0000 - accuracy: 0.8438\n",
      "Epoch 40: saving model to checkpoints/Optimization1/weights.40.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -8977157.0000 - accuracy: 0.8063\n",
      "Epoch 41/100\n",
      "39/69 [===============>..............] - ETA: 0s - loss: -9185637.0000 - accuracy: 0.8189\n",
      "Epoch 41: saving model to checkpoints/Optimization1/weights.41.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -9136756.0000 - accuracy: 0.8063\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -9298514.0000 - accuracy: 0.8063\n",
      "Epoch 43/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -7645169.5000 - accuracy: 0.8438\n",
      "Epoch 43: saving model to checkpoints/Optimization1/weights.43.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -9462581.0000 - accuracy: 0.8063\n",
      "Epoch 44/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -9810718.0000 - accuracy: 0.8438\n",
      "Epoch 44: saving model to checkpoints/Optimization1/weights.44.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -9627860.0000 - accuracy: 0.8063\n",
      "Epoch 45/100\n",
      "44/69 [==================>...........] - ETA: 0s - loss: -9919463.0000 - accuracy: 0.8139 \n",
      "Epoch 45: saving model to checkpoints/Optimization1/weights.45.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -9796019.0000 - accuracy: 0.8063\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -9965783.0000 - accuracy: 0.8063\n",
      "Epoch 47/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -12409731.0000 - accuracy: 0.7500\n",
      "Epoch 47: saving model to checkpoints/Optimization1/weights.47.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -10137431.0000 - accuracy: 0.8063\n",
      "Epoch 48/100\n",
      "42/69 [=================>............] - ETA: 0s - loss: -10123278.0000 - accuracy: 0.8103\n",
      "Epoch 48: saving model to checkpoints/Optimization1/weights.48.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -10311425.0000 - accuracy: 0.8063\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -10487007.0000 - accuracy: 0.8063\n",
      "Epoch 50/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -7945907.0000 - accuracy: 0.6875\n",
      "Epoch 50: saving model to checkpoints/Optimization1/weights.50.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -10665505.0000 - accuracy: 0.8063\n",
      "Epoch 51/100\n",
      "39/69 [===============>..............] - ETA: 0s - loss: -10806490.0000 - accuracy: 0.8037\n",
      "Epoch 51: saving model to checkpoints/Optimization1/weights.51.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -10845008.0000 - accuracy: 0.8063\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -11027280.0000 - accuracy: 0.8063\n",
      "Epoch 53/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -12833028.0000 - accuracy: 0.7500\n",
      "Epoch 53: saving model to checkpoints/Optimization1/weights.53.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -11211236.0000 - accuracy: 0.8063\n",
      "Epoch 54/100\n",
      "41/69 [================>.............] - ETA: 0s - loss: -11680263.0000 - accuracy: 0.8155\n",
      "Epoch 54: saving model to checkpoints/Optimization1/weights.54.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -11397071.0000 - accuracy: 0.8063\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -11585625.0000 - accuracy: 0.8063\n",
      "Epoch 56/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -11994364.0000 - accuracy: 0.9062\n",
      "Epoch 56: saving model to checkpoints/Optimization1/weights.56.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -11775238.0000 - accuracy: 0.8063\n",
      "Epoch 57/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -10580896.0000 - accuracy: 0.8438\n",
      "Epoch 57: saving model to checkpoints/Optimization1/weights.57.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -11967826.0000 - accuracy: 0.8063\n",
      "Epoch 58/100\n",
      "42/69 [=================>............] - ETA: 0s - loss: -12286190.0000 - accuracy: 0.8140\n",
      "Epoch 58: saving model to checkpoints/Optimization1/weights.58.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -12161613.0000 - accuracy: 0.8063\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -12358223.0000 - accuracy: 0.8063\n",
      "Epoch 60/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -12588153.0000 - accuracy: 0.6875\n",
      "Epoch 60: saving model to checkpoints/Optimization1/weights.60.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -12556071.0000 - accuracy: 0.8063\n",
      "Epoch 61/100\n",
      "43/69 [=================>............] - ETA: 0s - loss: -12813988.0000 - accuracy: 0.8052\n",
      "Epoch 61: saving model to checkpoints/Optimization1/weights.61.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -12756803.0000 - accuracy: 0.8063\n",
      "Epoch 62/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -12958735.0000 - accuracy: 0.8063\n",
      "Epoch 63/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -15523166.0000 - accuracy: 0.8438\n",
      "Epoch 63: saving model to checkpoints/Optimization1/weights.63.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -13163822.0000 - accuracy: 0.8063\n",
      "Epoch 64/100\n",
      "40/69 [================>.............] - ETA: 0s - loss: -13404850.0000 - accuracy: 0.8055\n",
      "Epoch 64: saving model to checkpoints/Optimization1/weights.64.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -13370271.0000 - accuracy: 0.8063\n",
      "Epoch 65/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -13579221.0000 - accuracy: 0.8063\n",
      "Epoch 66/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -14267280.0000 - accuracy: 0.7500\n",
      "Epoch 66: saving model to checkpoints/Optimization1/weights.66.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -13790195.0000 - accuracy: 0.8063\n",
      "Epoch 67/100\n",
      "40/69 [================>.............] - ETA: 0s - loss: -13792669.0000 - accuracy: 0.8062\n",
      "Epoch 67: saving model to checkpoints/Optimization1/weights.67.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -14003179.0000 - accuracy: 0.8063\n",
      "Epoch 68/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -14218084.0000 - accuracy: 0.8063\n",
      "Epoch 69/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -12738970.0000 - accuracy: 0.7188\n",
      "Epoch 69: saving model to checkpoints/Optimization1/weights.69.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -14435030.0000 - accuracy: 0.8063\n",
      "Epoch 70/100\n",
      "28/69 [===========>..................] - ETA: 0s - loss: -14423329.0000 - accuracy: 0.8080\n",
      "Epoch 70: saving model to checkpoints/Optimization1/weights.70.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -14654426.0000 - accuracy: 0.8063\n",
      "Epoch 71/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -14875862.0000 - accuracy: 0.8063\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: saving model to checkpoints/Optimization1/weights.72.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -15099529.0000 - accuracy: 0.8063\n",
      "Epoch 73/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -14316278.0000 - accuracy: 0.8438\n",
      "Epoch 73: saving model to checkpoints/Optimization1/weights.73.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -15324548.0000 - accuracy: 0.8063\n",
      "Epoch 74/100\n",
      "42/69 [=================>............] - ETA: 0s - loss: -15156984.0000 - accuracy: 0.7984\n",
      "Epoch 74: saving model to checkpoints/Optimization1/weights.74.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -15552980.0000 - accuracy: 0.8063\n",
      "Epoch 75/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -15782248.0000 - accuracy: 0.8063\n",
      "Epoch 76/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -18019868.0000 - accuracy: 0.8438\n",
      "Epoch 76: saving model to checkpoints/Optimization1/weights.76.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -16014154.0000 - accuracy: 0.8063\n",
      "Epoch 77/100\n",
      "39/69 [===============>..............] - ETA: 0s - loss: -16053703.0000 - accuracy: 0.8117\n",
      "Epoch 77: saving model to checkpoints/Optimization1/weights.77.hdf5\n",
      "69/69 [==============================] - 0s 3ms/step - loss: -16248596.0000 - accuracy: 0.8063\n",
      "Epoch 78/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -16484986.0000 - accuracy: 0.8063\n",
      "Epoch 79/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -19049020.0000 - accuracy: 0.7188\n",
      "Epoch 79: saving model to checkpoints/Optimization1/weights.79.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -16723309.0000 - accuracy: 0.8063\n",
      "Epoch 80/100\n",
      "40/69 [================>.............] - ETA: 0s - loss: -17050414.0000 - accuracy: 0.8102\n",
      "Epoch 80: saving model to checkpoints/Optimization1/weights.80.hdf5\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -16964258.0000 - accuracy: 0.8063\n",
      "Epoch 81/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -17207504.0000 - accuracy: 0.8063\n",
      "Epoch 82/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -14172414.0000 - accuracy: 0.8125\n",
      "Epoch 82: saving model to checkpoints/Optimization1/weights.82.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -17452782.0000 - accuracy: 0.8063\n",
      "Epoch 83/100\n",
      "28/69 [===========>..................] - ETA: 0s - loss: -17629508.0000 - accuracy: 0.7991\n",
      "Epoch 83: saving model to checkpoints/Optimization1/weights.83.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -17700344.0000 - accuracy: 0.8063\n",
      "Epoch 84/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -17949602.0000 - accuracy: 0.8063\n",
      "Epoch 85/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -19532348.0000 - accuracy: 0.6875\n",
      "Epoch 85: saving model to checkpoints/Optimization1/weights.85.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -18201448.0000 - accuracy: 0.8063\n",
      "Epoch 86/100\n",
      "31/69 [============>.................] - ETA: 0s - loss: -19185724.0000 - accuracy: 0.8145\n",
      "Epoch 86: saving model to checkpoints/Optimization1/weights.86.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -18455962.0000 - accuracy: 0.8063\n",
      "Epoch 87/100\n",
      "31/69 [============>.................] - ETA: 0s - loss: -18307728.0000 - accuracy: 0.8065\n",
      "Epoch 87: saving model to checkpoints/Optimization1/weights.87.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -18712250.0000 - accuracy: 0.8063\n",
      "Epoch 88/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -18970776.0000 - accuracy: 0.8063\n",
      "Epoch 89/100\n",
      "23/69 [=========>....................] - ETA: 0s - loss: -19554594.0000 - accuracy: 0.7880\n",
      "Epoch 89: saving model to checkpoints/Optimization1/weights.89.hdf5\n",
      "69/69 [==============================] - 0s 3ms/step - loss: -19231416.0000 - accuracy: 0.8063\n",
      "Epoch 90/100\n",
      "41/69 [================>.............] - ETA: 0s - loss: -18987494.0000 - accuracy: 0.7980\n",
      "Epoch 90: saving model to checkpoints/Optimization1/weights.90.hdf5\n",
      "69/69 [==============================] - 0s 3ms/step - loss: -19494486.0000 - accuracy: 0.8063\n",
      "Epoch 91/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -19759652.0000 - accuracy: 0.8063\n",
      "Epoch 92/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -16766311.0000 - accuracy: 0.7812\n",
      "Epoch 92: saving model to checkpoints/Optimization1/weights.92.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -20027470.0000 - accuracy: 0.8063\n",
      "Epoch 93/100\n",
      "36/69 [==============>...............] - ETA: 0s - loss: -20097800.0000 - accuracy: 0.8047\n",
      "Epoch 93: saving model to checkpoints/Optimization1/weights.93.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -20296920.0000 - accuracy: 0.8063\n",
      "Epoch 94/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: -20569254.0000 - accuracy: 0.8063\n",
      "Epoch 95/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -15155030.0000 - accuracy: 0.6875\n",
      "Epoch 95: saving model to checkpoints/Optimization1/weights.95.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -20843448.0000 - accuracy: 0.8063\n",
      "Epoch 96/100\n",
      "39/69 [===============>..............] - ETA: 0s - loss: -20629206.0000 - accuracy: 0.8045\n",
      "Epoch 96: saving model to checkpoints/Optimization1/weights.96.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -21120638.0000 - accuracy: 0.8063\n",
      "Epoch 97/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -21398946.0000 - accuracy: 0.8063\n",
      "Epoch 98/100\n",
      " 1/69 [..............................] - ETA: 0s - loss: -12283995.0000 - accuracy: 0.7500\n",
      "Epoch 98: saving model to checkpoints/Optimization1/weights.98.hdf5\n",
      "69/69 [==============================] - 0s 2ms/step - loss: -21681394.0000 - accuracy: 0.8063\n",
      "Epoch 99/100\n",
      "30/69 [============>.................] - ETA: 0s - loss: -21709688.0000 - accuracy: 0.8073\n",
      "Epoch 99: saving model to checkpoints/Optimization1/weights.99.hdf5\n",
      "69/69 [==============================] - 0s 3ms/step - loss: -21964180.0000 - accuracy: 0.8063\n",
      "Epoch 100/100\n",
      "54/69 [======================>.......] - ETA: 0s - loss: -22163728.0000 - accuracy: 0.8032\n",
      "Epoch 100: saving model to checkpoints/Optimization1/weights.100.hdf5\n",
      "69/69 [==============================] - 0s 3ms/step - loss: -22250756.0000 - accuracy: 0.8063\n"
     ]
    }
   ],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs('checkpoints/Optimization1/',exist_ok=True)\n",
    "checkpoint_path = 'checkpoints/Optimization1/weights.{epoch:02d}.hdf5'\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=100)\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5_POsgaaWB_",
    "outputId": "90b743b3-31b7-47eb-97c4-a54b242a831f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - loss: -4.1633e+06 - accuracy: 0.1946 - 727ms/epoch - 32ms/step\n",
      "Loss: -4163334.5, Accuracy: 0.1945578157901764\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GyAoR4RHaWcW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: groupprojectMachineLearning_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save('groupprojectMachineLearning_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
